{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8fb4f7a-8a81-4a24-a5c3-2b444d449a7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Aconex Mails Extraction\n",
    "\n",
    "### Summary\n",
    "This notebook uses Aconex API for 2 purposes:\n",
    "1. Extract list of mails exchanged since last refresh date. This uses an API call that returns list of mails (paged) in a response with basic details about each mail.\n",
    "2. Extract detailed information for each mail like custom fields and field like `DocumentID`, which is used to build a mapping table to connect to the Aconex Document data. This uses API calls for each mail that returns metadata of a mail with all the fields related to a mail.\n",
    "\n",
    "### Input\n",
    "> _No external input required._\n",
    "\n",
    "### API\n",
    "- API Vendor: Oracle Aconex\n",
    "- Authentication: Basic (API key and credentials)\n",
    "\n",
    "### The Execution Flow\n",
    "1. Get last refresh date from lastRefreshDate delta table and use it to find out the number of pages using a basic GET API call with date filter parameter.\n",
    "2. Loop through the range of total pages.\n",
    "    - Perform GET call using the current page number.\n",
    "3. Loop through the list of mails in current page, within the main loop.\n",
    "    - Perform GET call using the `MailID` for each mail to get metadata and additional fields.\n",
    "4. Store the required fields of each mail in a dataframe of mails and record the required fields for mapping in a dataframe of mapping table.\n",
    "5. After completing the first loop, convert the 2 dataframes into spark dataframes.\n",
    "6. Append the spark dataframes to respective delta tables. Replace the last refresh date with current date in the last refresh date delta table.\n",
    "\n",
    "### Output\n",
    "3 Delta tables:\n",
    "- `dev.dept.aconex_mails`\n",
    "- `dev.dept.aconex_map`\n",
    "- `dev.dept.aconex_mails_lastrefreshdate`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6c8453c-bda3-4e67-a307-c23c9ee353d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Code Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "085b9336-63f3-4c82-98cf-85e45f6955a5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Library Installation"
    }
   },
   "outputs": [],
   "source": [
    "!pip install xmltodict\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "e06eeafe-662c-40ee-887d-b08bbc52882e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Library Imports"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from cryptography.fernet import Fernet\n",
    "import xmltodict\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d3f963f-7daa-435e-bed4-3201f64c26f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "1ea155a4-6838-4a71-844f-00600161beb9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Global Variables"
    }
   },
   "outputs": [],
   "source": [
    "# Credentials\n",
    "KEY = \"KEY\"\n",
    "TOKEN = \"TOKEN\"\n",
    "API_KEY = \"API KEY\"\n",
    "\n",
    "# Delta tables\n",
    "mails_lastRefreshDate_catalog = \"dev.dept.aconex_mails_lastrefreshdate\"\n",
    "mails_table_catalog = \"dev.dept.aconex_mails\"\n",
    "map_table_catalog = \"dev.dept.aconex_map\"\n",
    "\n",
    "mails_delta_df = spark.read.table(mails_table_catalog).toPandas()\n",
    "\n",
    "# Required dates\n",
    "lastRefreshDate_df = spark.read.table(mails_lastRefreshDate_catalog).toPandas()\n",
    "lastRefreshDate = lastRefreshDate_df.iloc[0,0]\n",
    "todayDate = datetime.today().strftime(\"%Y%m%d\")\n",
    "\n",
    "# Delta table schemas\n",
    "MAIL_SCHEMA = StructType([\n",
    "    StructField(\"Column1\", StringType(), True),\n",
    "    StructField(\"Column2\", StringType(), True),\n",
    "    StructField(\"Column3\", StringType(), True),\n",
    "    StructField(\"Column4\", StringType(), True),\n",
    "    StructField(\"Column5\", StringType(), True),\n",
    "    StructField(\"Column6\", StringType(), True),\n",
    "    StructField(\"Column7\", StringType(), True),\n",
    "    StructField(\"Column8\", StringType(), True),\n",
    "    StructField(\"Column9\", StringType(), True),\n",
    "    StructField(\"Column10\", StringType(), True),\n",
    "    StructField(\"Column11\", StringType(), True),\n",
    "    StructField(\"Column12\", StringType(), True),\n",
    "    StructField(\"Column13\", StringType(), True),\n",
    "    StructField(\"Column14\", StringType(), True),\n",
    "    StructField(\"Column15\", StringType(), True),\n",
    "    StructField(\"Column16\", StringType(), True),\n",
    "    StructField(\"Column17\", StringType(), True),\n",
    "    StructField(\"Column18\", StringType(), True),\n",
    "    StructField(\"Column19\", StringType(), True),\n",
    "    StructField(\"Column20\", StringType(), True)\n",
    "])\n",
    "\n",
    "MAP_SCHEMA = StructType([\n",
    "    StructField(\"Column1\", StringType(), True),\n",
    "    StructField(\"Column2\", StringType(), True),\n",
    "    StructField(\"Column3\", StringType(), True),\n",
    "    StructField(\"Column4\", StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d224c64-60ef-4a7a-aae4-3caf79f36c1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Function Definitions\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "6d28a5ed-4bab-453d-9348-ad7c08cf6307",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function Definitions"
    }
   },
   "outputs": [],
   "source": [
    "def get_mail_response(mail_box, page_number = 1, max_page_size = 500, last_refresh_date=lastRefreshDate, today_date=todayDate):\n",
    "    # URL\n",
    "    mails_url = \"https://ca1.aconex.com/api/projects/<project id>/mail\"\n",
    "\n",
    "    # Headers\n",
    "    headers = {\n",
    "        \"X-Application-Key\": API_KEY\n",
    "    }\n",
    "\n",
    "    # Authorization\n",
    "    auth = HTTPBasicAuth(\"username\", Fernet(KEY).decrypt(TOKEN).decode())\n",
    "\n",
    "    # Parameters\n",
    "    params = {\n",
    "        \"mail_box\": mail_box,\n",
    "        \"return_fields\": \"identifier1,identifier2,identifier3,identifier4,identifier5,identifier6,identifier7,identifier8,identifier9,identifier10,identifier11\",\n",
    "        \"search_type\": \"PAGED\",\n",
    "        \"page_size\": max_page_size,\n",
    "        \"page_number\": page_number,\n",
    "        \"sort_field\": \"sentdate\",\n",
    "        \"search_query\": f\"sentdate:[{last_refresh_date}000000 TO {today_date}000000]\"\n",
    "    }\n",
    "\n",
    "    # Get and parse api response\n",
    "    response_raw = requests.get(mails_url, headers=headers, auth=auth, params=params)\n",
    "    while response_raw.status_code != 200:\n",
    "        print(\"\\t- Retrying | Status Code:\", response_raw.status_code)\n",
    "        response_raw = requests.get(mails_url, headers=headers, auth=auth, params=params)\n",
    "    #print(\"\\t- Response received | Status Code:\", response_raw.status_code)\n",
    "\n",
    "    response_parsed = xmltodict.parse(response_raw.text.replace(\"\\x02\",\" \"), encoding='utf-8')\n",
    "    #print(\"\\t- Response parsed to dict\")\n",
    "\n",
    "    return response_parsed, response_raw.status_code\n",
    "\n",
    "\n",
    "def get_mail_details(mail_id:str):\n",
    "    mail_url = f\"https://ca1.aconex.com/api/projects/1879053393/mail/{mail_id}\"\n",
    "    headers = {\"X-Application-Key\": \"API KEY\"}\n",
    "    auth = HTTPBasicAuth(\"mpatel\", Fernet(KEY).decrypt(TOKEN).decode())\n",
    "\n",
    "    mail_response = requests.get(mail_url, headers=headers, auth=auth)\n",
    "    while mail_response.status_code != 200:\n",
    "        mail_response = requests.get(mail_url, headers=headers, auth=auth)\n",
    "\n",
    "    mail_response = xmltodict.parse(mail_response.text.replace(\"\\x02\",\" \"), encoding='utf-8')\n",
    "\n",
    "    return mail_response\n",
    "\n",
    "\n",
    "def extract_default_fields(mail_dict):\n",
    "    default_field_values = [mail_dict['Column1'],mail_dict['Column2'],mail_dict['Column3'],mail_dict['Column4'],mail_dict['Column5'],\n",
    "                            mail_dict['Column6']['Column6.1'] if 'Column6' in list(mail_dict) else \"\",\n",
    "                            mail_dict['Column7']['Column7.1'] if 'Column7' in list(mail_dict) else \"\",\n",
    "                            mail_dict['Column8']['Column8.1'] if 'Column8' in list(mail_dict) else \"\",\n",
    "                            mail_dict['Column9'],mail_dict['Column10']]\n",
    "    return default_field_values\n",
    "\n",
    "\n",
    "def extract_custom_fields(custom_fields_dict):\n",
    "    if type(custom_fields_dict) == dict:\n",
    "        custom_fields_dict = [custom_fields_dict]\n",
    "    cf_labels = [c['Label'] for c in custom_fields_dict]\n",
    "    cf = {item['Label']: item['Value'] for item in custom_fields_dict}\n",
    "\n",
    "    custom_field_values = [cf['Column11'] if 'Column11' in cf_labels else \"\",\n",
    "                        cf['Column12'] if 'Column12' in cf_labels else \"\",\n",
    "                        cf['Column13'] if 'Column13' in cf_labels else \"\",\n",
    "                        cf['Column14'] if 'Column14' in cf_labels else \"\",\n",
    "                        cf['Column15'] if 'Column15' in cf_labels else \"\",\n",
    "                        cf['Column16'] if 'Column16' in cf_labels else \"\",\n",
    "                        cf['Column17'] if 'Column17' in cf_labels else \"\"]\n",
    "    return custom_field_values\n",
    "\n",
    "\n",
    "def get_attachment_details(attachment_count,attachment_details,cols,mail_id, mail_no):\n",
    "    attachment_data_list = []\n",
    "\n",
    "    if int(attachment_count) == 1:                      # One Attachment\n",
    "        if \"DocumentId\" in list(attachment_details):\n",
    "            attachment_data_list.append([mail_id, mail_no, attachment_details['DocumentId'], attachment_details['DocumentNo']])\n",
    "        elif \"RegisteredAs\" in list(attachment_details):\n",
    "            attachment_data_list.append([mail_id, mail_no, attachment_details['RegisteredAs'], attachment_details['DocumentNo']])\n",
    "\n",
    "    elif int(attachment_count) > 1:                     # Multiple Attachments\n",
    "        for j in attachment_details:\n",
    "            if \"RegisteredAs\" in list(j):\n",
    "                attachment_data_list.append([mail_id, mail_no, j['RegisteredAs'], j['DocumentNo']])\n",
    "            elif \"DocumentId\" in list(j):\n",
    "                attachment_data_list.append([mail_id, mail_no, j['DocumentId'], j['DocumentNo']])\n",
    "\n",
    "    return pd.DataFrame(attachment_data_list,columns=cols)\n",
    "\n",
    "\n",
    "def extract_recipients(rcpt_value):\n",
    "    if type(rcpt_value) == list:\n",
    "        return ', '.join([f\"{r['Name']} - {r['OrganizationName']}\" for r in rcpt_value])\n",
    "    elif type(rcpt_value) == dict:\n",
    "        return f\"{rcpt_value['Name']} - {rcpt_value['OrganizationName']}\"\n",
    "\n",
    "\n",
    "def extract_senttomx(rcpt_value):\n",
    "    if type(rcpt_value) == list:\n",
    "        return '1879056043' in [r['OrganizationId'] for r in rcpt_value]\n",
    "    elif type(rcpt_value) == dict:\n",
    "        return '1879056043' == rcpt_value['OrganizationId']\n",
    "\n",
    "\n",
    "def sparkify_df(df,schema=None):\n",
    "    return spark.createDataFrame(df,schema=schema)\n",
    "\n",
    "\n",
    "def push_data(spark_df,mode,delta_table_name,mergeSchema=\"true\"):\n",
    "    try:\n",
    "        spark_df.write.option(\"delta.columnMapping.mode\", \"name\").option(\"mergeSchema\", mergeSchema).mode(mode).saveAsTable(delta_table_name)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Data push failed:\\n\\t{e}\")\n",
    "\n",
    "\n",
    "def check_duplicate_mails(df):\n",
    "    if len(df['MailID']) == len(set(df['MailID'])):\n",
    "        print(f\"No duplicates. {len(df['MailID'])} records.\")\n",
    "    else:\n",
    "        print(f\"Duplicates found.\")\n",
    "        print(f\"Total: {len(df['MailID'])}\")\n",
    "        print(f\"Distinct: {len(set(df['MailID']))}\")\n",
    "\n",
    "\n",
    "def df_batcher(df, batch_size):\n",
    "    batches = []\n",
    "    total_batches = len(df) // batch_size + (1 if len(df) % batch_size != 0 else 0)\n",
    "    for i in range(total_batches):\n",
    "        start_index = i * batch_size\n",
    "        end_index = start_index + batch_size\n",
    "        batches.append(df[start_index:end_index])\n",
    "    return batches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba5d85be-f792-4e07-ab04-14cdf69cadf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Main\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "1d11993d-57db-4032-b4e1-d0330b07922a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Main Prep"
    }
   },
   "outputs": [],
   "source": [
    "# Define dataframes to store data\n",
    "map_cols = ['Column1','Column2','Column3','Column4']\n",
    "mail_cols = ['Column1','Column2','Column3','Column4','Column5','Column6','Column7','Column8','Column9','Column10','Column11','Column12','Column13','Column14','Column15','Column16','Column17','Column18','Column19','Column20']\n",
    "\n",
    "df_map = pd.DataFrame(columns=map_cols)\n",
    "df_mail = pd.DataFrame(columns=mail_cols)\n",
    "\n",
    "# List of mail boxes to get mails from\n",
    "mail_boxes = ['inbox', 'sentbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "87ad6c7f-d12f-431f-92b8-f80e34c6cdee",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Main Execution"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate through the list of mail boxes\n",
    "for mailbox in mail_boxes:\n",
    "    response, status_code = get_mail_response(mailbox)\n",
    "    total_pages = int(response['MailSearch']['@TotalPages'])\n",
    "    print(f\"Fetching from {mailbox} ({total_pages} pages):\")\n",
    "\n",
    "    # Define progress bar\n",
    "    total_results = int(response['MailSearch']['@TotalResults'])\n",
    "    progress = tqdm(total=total_results, desc=f\"Mails from {mailbox}\")\n",
    "\n",
    "    # Iterate through the range of total number of pages\n",
    "    for page_num in range(1,total_pages+1):\n",
    "        print(f\"- Page {page_num}:\",end=\"\\n\")\n",
    "        response, status_code = get_mail_response(mailbox, page_number=page_num)\n",
    "\n",
    "        # Store list of mail details from the page\n",
    "        page_content = response['MailSearch']['SearchResults']['Mail']\n",
    "\n",
    "        # Iterate through the list of mail details dictionaries per mail\n",
    "        for i in page_content:\n",
    "            tmp_mail_id = i['@MailId']\n",
    "            \n",
    "            # Process Mail only if not in either existing mails' dataframe or existing delta table dataframe\n",
    "            if tmp_mail_id in df_mail['MailID'].values or tmp_mail_id in mails_delta_df['MailID'].values:\n",
    "                print('.', end=' ')\n",
    "            \n",
    "            else:\n",
    "\n",
    "                try:\n",
    "                    temp_mail, temp_cf = ([],['']*7)\n",
    "                    mail_details = get_mail_details(tmp_mail_id)['Mail']\n",
    "\n",
    "                    # Extract mail data and populate df_mail\n",
    "                    ### List default field values\n",
    "                    temp_mail = extract_default_fields(i)\n",
    "\n",
    "                    ### List custom field values if present\n",
    "                    if 'CustomFields' in list(mail_details):\n",
    "                        temp_cf = extract_custom_fields(mail_details['CustomFields']['CustomField'])\n",
    "\n",
    "                    ### Extract additional values related to recipients\n",
    "                    senttomx = [str(extract_senttomx(mail_details['ToUsers']['Recipient']))]\n",
    "                    recipients = [extract_recipients(mail_details['ToUsers']['Recipient'])]\n",
    "\n",
    "                    # Append full mails data row to mails df\n",
    "                    df_mail.loc[len(df_mail)] = temp_mail + temp_cf + senttomx + recipients + [mailbox]\n",
    "\n",
    "                    # Extract mapping data and populate df_map\n",
    "                    if i['AttachedDocumentCount'] != \"0\":\n",
    "                        attachment_data = mail_details['Attachments']['RegisteredDocumentAttachment']\n",
    "                        temp_df_map = get_attachment_details(i['AttachedDocumentCount'], attachment_data, map_cols, tmp_mail_id, i['MailNo'])\n",
    "                        df_map = pd.concat([df_map, temp_df_map], ignore_index=True)\n",
    "                    \n",
    "                    print('|', end=' ')\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Exception occurred while processing - {tmp_mail_id}\")\n",
    "                    print(e, end=\"\\n\\n\")\n",
    "            \n",
    "            progress.update(1)\n",
    "        \n",
    "        print(\" X\\n\")\n",
    "\n",
    "print(\"- - - EXECUTION COMPLETE - - -\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d890a03-8e78-412e-b6ae-27206de66c93",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Data Check"
    }
   },
   "outputs": [],
   "source": [
    "check_duplicate_mails(df_mail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "2b9e5c38-ac28-482d-88a2-ae8998e0d810",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Data Prep"
    }
   },
   "outputs": [],
   "source": [
    "# Remove duplicate rows\n",
    "df_mail.drop_duplicates(inplace=True)\n",
    "df_map.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save current date as last refresh date\n",
    "lastRefreshDate_df.iloc[0,0] = todayDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "c298e98a-9c42-432a-9e9a-51a3c37e984c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Data Save"
    }
   },
   "outputs": [],
   "source": [
    "# Update the delta tables with new data\n",
    "WriteMode = \"append\"\n",
    "\n",
    "push_data(\n",
    "    sparkify_df(df_mail, schema=MAIL_SCHEMA),\n",
    "    WriteMode,\n",
    "    mails_table_catalog,\n",
    "    mergeSchema=\"true\"\n",
    ")\n",
    "\n",
    "push_data(\n",
    "    sparkify_df(df_map, schema=MAP_SCHEMA),\n",
    "    WriteMode,\n",
    "    map_table_catalog,\n",
    "    mergeSchema=\"true\"\n",
    ")\n",
    "\n",
    "push_data(\n",
    "    sparkify_df(lastRefreshDate_df),\n",
    "    \"overwrite\",\n",
    "    mails_lastRefreshDate_catalog,\n",
    "    mergeSchema=\"true\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a93c5e4e-405d-4309-974d-ca74c2974725",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "ad7ae3c5-fde8-4ed2-9f7f-0ec4607e133c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "TEMP"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Temporary overwrite\n",
    "'''\n",
    "spark_map_df.write.option(\"delta.columnMapping.mode\", \"name\").mode(\"overwrite\").saveAsTable(map_table_catalog)\n",
    "spark_mail_df.write.option(\"delta.columnMapping.mode\", \"name\").option(\"mergeSchema\", \"true\").mode(\"overwrite\").saveAsTable(mails_table_catalog)\n",
    "'''\n",
    "\n",
    "# Temporary data save in batches\n",
    "'''\n",
    "df_batches = df_batcher(df_mail, 5000)\n",
    "count = 0\n",
    "sent_mails_table = 'dev.dept.aconex_sentmails'\n",
    "for t in trange(len(df_batches)):\n",
    "    spark_df = spark.createDataFrame(df_batches[t], schema=MAIL_SCHEMA)\n",
    "    if count == 0:\n",
    "        # Overwrite data for the first batch\n",
    "        spark_df.write.format(\"delta\").option(\"delta.columnMapping.mode\", \"name\").option(\"mergeSchema\", \"true\").mode(\"overwrite\").saveAsTable(sent_mails_table)\n",
    "    else:\n",
    "        # Append data for the rest of the batches\n",
    "        spark_df.write.format(\"delta\").option(\"delta.columnMapping.mode\", \"name\").option(\"mergeSchema\", \"true\").mode(\"append\").saveAsTable(sent_mails_table)\n",
    "    print(count)\n",
    "    count += 1\n",
    "'''\n",
    "\n",
    "# Temporary overwrite sent mails\n",
    "'''\n",
    "spark_df = spark.createDataFrame(df_mail,schema=MAIL_SCHEMA)\n",
    "spark_df.write.option(\"delta.columnMapping.mode\", \"name\").option(\"mergeSchema\", 'true').mode('overwrite').saveAsTable('dev.dept.aconex_sentmails')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "23a27cd4-352a-4025-8a55-c30c82b87c93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--SELECT YEAR(DATE(SentDate)) as _Year, count(MailID) as Total_Count FROM dev.dept.aconex_mails GROUP BY _Year;\n",
    "--SELECT * from dev.dept.aconex_mails where YEAR(SentDate) = 2025 and MONTH(SentDate) = 5 sort by SentDate desc;\n",
    "--SELECT count(MailID) as Total_Count, count(DISTINCT(MailID)) as Disctinct_Count FROM dev.dept.aconex_mails;\n",
    "--SELECT MailBox, count(*) as totalCount FROM dev.dept.aconex_sentmails group by MailBox;\n",
    "\n",
    "-- Enable column mapping\n",
    "--ALTER TABLE dev.dept.aconex_mails SET TBLPROPERTIES ('delta.columnMapping.mode' = 'name');\n",
    "-- Rename the column\n",
    "--ALTER TABLE dev.dept.aconex_mails RENAME COLUMN Reponse TO Response;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8686596481630690,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Aconex Mails Extraction",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
